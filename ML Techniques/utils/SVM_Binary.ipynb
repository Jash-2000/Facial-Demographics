{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Binary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDE2tauc5d78"
      },
      "source": [
        "'''   \n",
        "    Importing the google drive on google colab\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90eczM07ATPe"
      },
      "source": [
        "#Importing other libraries.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7psbjbw_9P-i"
      },
      "source": [
        "# importing the dataset for training and testing.\n",
        "\n",
        "df_train = pd.read_csv(\"/drive/My Drive/ML Data/mnist_train.csv\")\n",
        "df_test = pd.read_csv(\"/drive/My Drive/ML Data/mnist_test.csv\")\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm600DlnDZ2A"
      },
      "source": [
        "Droppin the Null values\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUXfjSOQANiL"
      },
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)\n",
        "\n",
        "# Dropping the rows with error values\n",
        "train_new = df_train.dropna()\n",
        "test_new = df_test.dropna()\n",
        "\n",
        "print(\"New shapes : \\n\")\n",
        "print(train_new.shape)\n",
        "print(test_new.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP5FSrZOFJ73"
      },
      "source": [
        "Clearly, none of the rows has an error value in it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oCzw48JFvBg"
      },
      "source": [
        "EDA of the data set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PldksWDDD0Gc"
      },
      "source": [
        "print(train_new.info())\n",
        "\n",
        "train_new.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkDaNI9wFXXP"
      },
      "source": [
        "# Splitting the labels from the data\n",
        "\n",
        "train = train_new.iloc[:,1:]\n",
        "train_label = train_new.iloc[:,0]\n",
        "\n",
        "test = test_new.iloc[:,1:]\n",
        "test_label = test_new.iloc[:,0]\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE5zQzcc-0ui"
      },
      "source": [
        "train_label.columns = ['label']\n",
        "train_label.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1NWB4puChI"
      },
      "source": [
        "# Watching an image now\n",
        "\n",
        "trial = train.iloc[69,:]\n",
        "trial = trial.values.reshape(28, 28)\n",
        "plt.imshow(trial, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpVrhwvsGQiu"
      },
      "source": [
        "# developing a countplot and displaying the count values\n",
        "\n",
        "i = 0\n",
        "for i in range(10):\n",
        "  count = train_label.loc[train_label == i ]\n",
        "  print(\"Value\",i,\" : \", len(count))\n",
        "\n",
        "sns.countplot(train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vLc5YwJtJY_"
      },
      "source": [
        "# data normalization and scaling\n",
        "\n",
        "train = train/255\n",
        "test = test/255\n",
        "\n",
        "# Doubt - why scale now?\n",
        "\n",
        "from sklearn.preprocessing import scale\n",
        "train = scale(train)\n",
        "test = scale(test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoNIs1Jl6KTN"
      },
      "source": [
        "# linear model\n",
        "\n",
        "model_linear = SVC(kernel='linear')\n",
        "model_linear.fit(train, train_label)\n",
        "\n",
        "# predict\n",
        "y_pred = model_linear.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4uLeJoo6JYn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idG2aOISIDxV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "d9895cac-607a-4d75-c6df-be2123a1ed37"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "'''\n",
        "from sklearn.metrix import classification_report\n",
        "print(classification_report(y_test, y_fit, target_label))\n",
        "''''\n",
        "# accuracy\n",
        "print(\"accuracy:\", metrics.accuracy_score(y_true=test_label, y_pred=y_pred), \"\\n\")\n",
        "\n",
        "cm = metrics.confusion_matrix(y_true = test_label, y_pred=y_pred)\n",
        "# Printing the sensitivities\n",
        "\n",
        "col_sum = cm.sum(axis = 0)\n",
        "i = 0\n",
        "for i in range(10):\n",
        "  sens = cm[i,i] / col_sum[i]\n",
        "  print(\"Sensitivity for\",i,\"is : \",round(sens, 3))  \n",
        "print('\\n')\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.928 \n",
            "\n",
            "Sensitivity for 0 is :  0.939\n",
            "Sensitivity for 1 is :  0.96\n",
            "Sensitivity for 2 is :  0.898\n",
            "Sensitivity for 3 is :  0.894\n",
            "Sensitivity for 4 is :  0.92\n",
            "Sensitivity for 5 is :  0.909\n",
            "Sensitivity for 6 is :  0.96\n",
            "Sensitivity for 7 is :  0.95\n",
            "Sensitivity for 8 is :  0.913\n",
            "Sensitivity for 9 is :  0.934\n",
            "\n",
            "\n",
            "[[ 953    0    6    2    1    8    6    2    1    1]\n",
            " [   0 1118    7    2    0    1    2    1    4    0]\n",
            " [   9   12  956   11    9    4    5    5   18    3]\n",
            " [   7    1   15  940    0   17    1    6   19    4]\n",
            " [   3    2   18    1  927    0    3    6    3   19]\n",
            " [   7    6    7   40    5  791   12    1   20    3]\n",
            " [  14    3   17    1    9   19  892    0    3    0]\n",
            " [   2    8   23   14   11    2    0  945    2   21]\n",
            " [  11    7   10   29    8   23    8    6  860   12]\n",
            " [   9    7    6   11   38    5    0   23   12  898]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76THR3TiMAk-"
      },
      "source": [
        "# Non linear model\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "folds = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
        "\n",
        "# Set the parameters by cross-validation\n",
        "hyper_params = [ {'gamma': [1e-1, 1e-2, 1e-3, 1e-4],\n",
        "                     'C': [5,10]}]\n",
        "\n",
        "\n",
        "# specify model\n",
        "model = SVC(kernel=\"rbf\")\n",
        "\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = model, \n",
        "                        param_grid = hyper_params, \n",
        "                        scoring= 'accuracy', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)      \n",
        "\n",
        "# fit the model\n",
        "model_cv.fit(train, train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxc4ju1APYon"
      },
      "source": [
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results\n",
        "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
        "\n",
        "# # plotting\n",
        "plt.figure(figsize=(16,10))\n",
        "\n",
        "# subplot 1/4\n",
        "plt.subplot(221)\n",
        "gamma_01 = cv_results[cv_results['param_gamma']==0.1]\n",
        "\n",
        "plt.plot(gamma_1[\"param_C\"], gamma_1[\"mean_test_score\"])\n",
        "plt.plot(gamma_1[\"param_C\"], gamma_1[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.1\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
        "plt.xscale('log')\n",
        "\n",
        "# subplot 2/4\n",
        "plt.subplot(222)\n",
        "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
        "\n",
        "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
        "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.01\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
        "plt.xscale('log')\n",
        "\n",
        "# subplot 3/4\n",
        "plt.subplot(223)\n",
        "gamma_01 = cv_results[cv_results['param_gamma']==0.001]\n",
        "\n",
        "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
        "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.001\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
        "plt.xscale('log')\n",
        "\n",
        "# subplot 4/4\n",
        "plt.subplot(224)\n",
        "gamma_01 = cv_results[cv_results['param_gamma']==0.0001]\n",
        "\n",
        "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
        "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Gamma=0.0001\")\n",
        "plt.ylim([0.60, 1])\n",
        "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
        "plt.xscale('log')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS279tpESHLD"
      },
      "source": [
        "#Modeling for best score\n",
        "\n",
        "C_best = model_cv.best_score_\n",
        "gamma_best = model_cv.best_params_\n",
        "\n",
        "\n",
        "model = SVC(C=C_best, gamma=gamma_best, kernel=\"rbf\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# metrics\n",
        "\n",
        "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred), \"\\n\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1cyqwQDT5at"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}